{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-2W919d2ZXp7"},"source":["# Homework 7: Classification"]},{"cell_type":"markdown","metadata":{"id":"L4nOzVhyZXqK"},"source":["This homework assignment is designed to give you practice with classification models. We'll try to predict which words are more likely to be responded to correctly during a lexical decision task, based on their length and frequency.\n","\n","We will be using data from the English Lexicon Project again. However, this time we will use response correctness as our dependent variable. Load **LexicalData_withIncorrect.csv**, which includes incorrect trials as well as correct ones, and also **Items.csv**. Both can be found in the *Homework/lexDat* folder in the class GitHub repository. \n","\n","This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides response correctness and reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). \n","\n","*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"]},{"cell_type":"markdown","metadata":{"id":"9DsyBTB6ZXqN"},"source":["---\n","# Loading and formatting the data (1 point)\n","\n","Load in data from the **LexicalData_withIncorrect.csv** and **Items.csv** files. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to the **LexicalData**, and use `drop_na()` to get rid of any observations with missing values. Then use `head()` to look at the first few rows of the data. \n","\n","*Note: We're just working with `Correct` in this homework, so no need to worry about reformatting reaction times.*"]},{"cell_type":"code","metadata":{"id":"UnBVazYfZXqP","executionInfo":{"status":"ok","timestamp":1616466897527,"user_tz":240,"elapsed":567,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}}},"source":["# WRITE YOUR CODE HERE"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BeK0H64WlOBM"},"source":["# Visualizing the data (1 point)"]},{"cell_type":"markdown","metadata":{"id":"dP_6o9rpmThw"},"source":["First, we'll try to visualize whether trials that are responded to correctly versus incorrectly differ from each other in terms of word length and log frequency. The code is included below, so that this homework doesn't get too cumbersome. All you have to do is **change the name of the data set**, **run the code**, and **write some observations about the output**."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"PIPheP5ipgKg","executionInfo":{"status":"error","timestamp":1616466921479,"user_tz":240,"elapsed":2598,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}},"outputId":"8a433ff4-1680-45fe-dead-2d37947e2d82"},"source":["# REPLACE \"fdata\" WITH THE NAME OF YOUR DATA SET\n","require(tidyverse) # Load the tidyverse package, if you haven't yet\n","fdata$Correct <- as.factor(fdata$Correct) # so that R knows that Correct is categorical, not numeric. \n","ggplot(fdata,aes(x=round(Log_Freq_HAL,1),y=Length,col=Correct)) + geom_point(position=\"jitter\",alpha=0.5) + theme_light() # plot the Correct / Incorrect clusters"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Loading required package: tidyverse\n","\n","Warning message in system(\"timedatectl\", intern = TRUE):\n","“running command 'timedatectl' had status 1”\n","── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n","\n","\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.3     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n","\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.0     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.5\n","\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n","\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n","\n","── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n","\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n","\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n","\n"],"name":"stderr"},{"output_type":"error","ename":"ERROR","evalue":"ignored","traceback":["Error in is.factor(x): object 'fdata' not found\nTraceback:\n","1. as.factor(fdata$Correct)","2. is.factor(x)"]}]},{"cell_type":"markdown","metadata":{"id":"8W0y8eRxTa6Z"},"source":["What do you observe about the \"Correct\" and \"Incorrect\" clusters? "]},{"cell_type":"markdown","metadata":{"id":"wWxi8O6voooe"},"source":["> *Your observations here.*"]},{"cell_type":"markdown","metadata":{"id":"T3b3_KsHk-xD"},"source":["# Logistic Regression\n","\n","## Fitting the model (2 points)"]},{"cell_type":"markdown","metadata":{"id":"hlahTNHxrJaR"},"source":["Fit a logistic regression model to the data using `Length`, `Log_Freq_HAL`, and their interaction to predict `Correct`. Use `glm()` to fit the model, and look at its output using `summary()`."]},{"cell_type":"code","metadata":{"id":"AidH_KidrX9L","executionInfo":{"status":"ok","timestamp":1616466960292,"user_tz":240,"elapsed":294,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}}},"source":["# WRITE YOUR CODE HERE"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9AC8nTnYtzAb"},"source":["What can you conclude from this output? (a brief gist is fine)"]},{"cell_type":"markdown","metadata":{"id":"9MLyXXTIuACv"},"source":["> *Your response here.*"]},{"cell_type":"markdown","metadata":{"id":"iCnLulvxA2fM"},"source":["## Interpreting predictions from the model (3 points)"]},{"cell_type":"markdown","metadata":{"id":"dCy9W_Mou4zT"},"source":["Finally, look at how well this logistic regression model does at predicting correctness. Use `predict()` and a threshold of 0.5 to generate predicted `Correct` values for each trial, then output a confusion matrix and overall accuracy for these predictions.\n","\n","*Hint: see Tutorial 13 on Classifiers.*"]},{"cell_type":"code","metadata":{"id":"nZQ2_WzixTJH","executionInfo":{"status":"ok","timestamp":1616466981966,"user_tz":240,"elapsed":466,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}}},"source":["# WRITE YOUR CODE HERE"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-D1Kk4Wz6eA"},"source":["Did the model do well at predicting lexical decision correctness? Why or why not? "]},{"cell_type":"markdown","metadata":{"id":"PHZnDFzV0K7K"},"source":["> *Your response here.*"]},{"cell_type":"markdown","metadata":{"id":"7_xE_hjFDMe-"},"source":["# QDA (3 points)"]},{"cell_type":"markdown","metadata":{"id":"FzvQBhcbD995"},"source":["Load in the `MASS` library and fit a QDA model to the data set. The predictors are still `Length`, `Log_Freq_HAL`, and their interaction, just like the logistic regression model you just ran, and the dependent variable is still `Correct`. \n","\n","*Hint: see Tutorial 13 on Classifiers*"]},{"cell_type":"code","metadata":{"id":"v5unJLgdERP_","executionInfo":{"status":"ok","timestamp":1616467019700,"user_tz":240,"elapsed":257,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}}},"source":["# WRITE YOUR CODE HERE"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YceNR0uSEquX"},"source":["Now look at how well the predicted `Correct` values compare with actual `Correct` values for the whole data set. Output a confusion matrix and overall prediction accuracy. "]},{"cell_type":"code","metadata":{"id":"tvhhrDWRF2hJ","executionInfo":{"status":"ok","timestamp":1616467028408,"user_tz":240,"elapsed":360,"user":{"displayName":"Patience Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64","userId":"01994571539255174942"}}},"source":["# WRITE YOUR CODE HERE"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"leurrTYKHBe_"},"source":["How does QDA prediction performance differ from that of logistic regression? For fun (no need to write anything), reason about why you think this happened."]},{"cell_type":"markdown","metadata":{"id":"j3BRrwUhHV1J"},"source":["> *Your response here.*"]},{"cell_type":"markdown","metadata":{"id":"C4MPECMmZXqe"},"source":["**DUE:** 5pm EST, April 1, 2021"]},{"cell_type":"markdown","metadata":{"id":"r9GUofXN4BVy"},"source":["**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n","> *Someone's Name*"]}]}