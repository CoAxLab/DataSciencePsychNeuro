{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-2W919d2ZXp7"},"source":["# Homework 3: Data visualization"]},{"cell_type":"markdown","metadata":{"id":"L4nOzVhyZXqK"},"source":["This homework assignment is designed to give you practice manipulating and visualizing data. \n","\n","You will need to download the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository. \n","\n","This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file. \n","\n","*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"]},{"cell_type":"markdown","metadata":{"id":"9DsyBTB6ZXqN"},"source":["---\n","## Loading the Data (1 point)\n","\n","Use the `setwd` (or `system (\"gdown\")` if you're working in colab) and `read.csv` functions to load data from the **LexicalData.csv** and **Items.csv** files. Then, as in the previous homework, remove the commas from the reaction times and convert them from strings to numbers. Use `head` to look at the first few rows of each data frame. \n","\n","*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"]},{"cell_type":"code","metadata":{"id":"UnBVazYfZXqP"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYP82lP2xxeZ"},"source":["## Reformatting the Data (1 points)"]},{"cell_type":"markdown","metadata":{"id":"-tKHdT1yiiXS"},"source":["First you'll need to load the `tidyverse` library."]},{"cell_type":"code","metadata":{"id":"QlrsT57ezHem"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6NT6luFpzNBF"},"source":[" In order to get some insights about what characteristics of words make them easier to recognize, it would be useful to have reaction times and word characteristics in the same data frame. Add the `Length` and `Log_Freq_HAL` variables from the items data frame to the reaction times data frame using `left_join()`. You may want to use `select()` and the piping operator `%>%`, as well."]},{"cell_type":"code","metadata":{"id":"ggVAFdHpyARn"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZWKJvEAz3ho"},"source":["## Visualizing the Data (7 points)\n","\n","Now, let's visualize some aspects of the data. For each of the following questions, use `ggplot2` to plot the data in a way that helps you answer the question. Then write a qualitative response to the question. **Keep in mind the 9 properties of graphical excellence as you make decisions for this section.**"]},{"cell_type":"markdown","metadata":{"id":"DT6lAYOi3pOG"},"source":["*Question 1:* How are the reaction time values distributed?"]},{"cell_type":"code","metadata":{"id":"rUV200cd1Mx2"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3C1lEKO3inD"},"source":["> *Write your response here.*\n"]},{"cell_type":"markdown","metadata":{"id":"tobT7Om65-43"},"source":["*Question 2:* Is there a relationship between word length and log frequency? If so, how would you describe it? "]},{"cell_type":"code","metadata":{"id":"k7_2JHLp1a0z"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7poMFemDHas"},"source":["> *Write your response here.*\n"]},{"cell_type":"markdown","metadata":{"id":"OcvWL1WuBDRA"},"source":["*Question 3:* What is the relationship between log word frequency and lexical decision reaction time? (hint: binning frequency and using `stat_summary` may be helpful)"]},{"cell_type":"code","metadata":{"id":"AFUo6B7z_la3"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ol1x6zmXDew3"},"source":["> *Write your response here.*\n"]},{"cell_type":"markdown","metadata":{"id":"4O-g6lsZDeD3"},"source":["*Question 4:* Is the overall relationship between log word frequency and lexical decision reaction time different for short words versus long words? (hint: try binning both length and frequency)"]},{"cell_type":"code","metadata":{"id":"MCVTYNXAFSqC"},"source":["#INSERT CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-PeK6J7FQcX"},"source":["> *Write your response here.*"]},{"cell_type":"markdown","metadata":{"id":"Esb1nqQ6y7jB"},"source":["## Reflection (1 point)\n","How might you approach analyzing this data differently after the insights you gained from these visualizations? "]},{"cell_type":"markdown","metadata":{"id":"fC1xhwBRzI99"},"source":["> *Write your response here.* "]},{"cell_type":"markdown","metadata":{"id":"C4MPECMmZXqe"},"source":["**DUE:** 5pm EST, March 4, 2021"]},{"cell_type":"markdown","metadata":{"id":"r9GUofXN4BVy"},"source":["**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n","> *Someone's Name*"]}]}