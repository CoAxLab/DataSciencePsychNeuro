{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0-Q9NYTBujb"
   },
   "source": [
    "# Homework 10: Regularized regression\n",
    "\n",
    "This homework assignment is designed to give you an intuition as an interesting property of regularization in the context of ultra-high dimensional statistical problems.\n",
    "\n",
    "You won't need to load in any data for this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bODln6rvBujd"
   },
   "source": [
    "---\n",
    "# Simulating & visualizing data (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sezRLzgHBuje"
   },
   "source": [
    "We are going to be looking at what happens in the context where $p>n$. In order to have total control over our data, we will use simulations for this homework. First, we will need to load the `glmnet`, `tidyverse`, and `ggplot2` libraries for this assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LVJwea2rBujf"
   },
   "outputs": [],
   "source": [
    "#Load libraries (install if not done already)\n",
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "\n",
    "# Let's also turn off warnings (we'll get them a lot in this assignment)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXwMchX7Bujf"
   },
   "source": [
    "We are going to generate a data set with complex structure and try to recover it using polynomial models. For simplicity sake, use the following code to produce a response variable, $y$ that has complex structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Look up what a cosine function looks like if you need a reminder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BeK03Sx7Bujg"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "set.seed(121)\n",
    "sigma_noise = .5\n",
    "x=seq(-9,9,by=.18)\n",
    "n=length(x)\n",
    "y = 0.1*x + cos(x) + cos(x/20)+rnorm(n,sd=sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfmUWGIlBujg"
   },
   "source": [
    "(a) Break the data into a training set (n=50) and test set (n=51) using the `sample` function to randomly select subsets of x and y.  Make a separate data frame for the training and test data.\n",
    "\n",
    "(**Note**: *Do not* just take the first 50 observations to be the training set and last 51 observations to be the test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rIg6XGaHBujg"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "# Create the test and training indices\n",
    "# Generate x_train, y_train, x_test, y_test fom the indices\n",
    "# Create df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ4B7a1lBujg"
   },
   "source": [
    "(b) Plot the training data ($x$ \\& $y$). Describe the relationship that you see in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hRyRddZJBujh",
    "outputId": "f2d5e3e9-1442-42f5-e4f1-ba0c26214259"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaVD7SEeBuji"
   },
   "source": [
    "How would you describe the relationship between $x$ and $y$ based on this plot?\n",
    "\n",
    "> *Your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqLPa45zBuji"
   },
   "source": [
    "\n",
    "---\n",
    "## Bias-variance tradeoff: polynomial regression (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in polynomial regression we increase model complexity by expanding $x$ out to the power $k$ (which we call degree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$Y = \\hat{\\beta}_0 + \\sum_{j=1}^K \\hat{\\beta}_jX^j $$  \n",
    "\n",
    "$$ = poly(x,k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SvSDGa9Buji"
   },
   "source": [
    "(a) Fit a 2nd degree polynomial regression model to the training data. Plot the results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: Use the* `help` *function to see how to use the* `stat_smooth()` *and* `poly()` *functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R_mZIsWwBuji",
    "outputId": "437dba9e-5f9d-4902-ef81-56e721dae29e"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYxz29TyBujj"
   },
   "source": [
    "How well does this 2nd degree polynomial model qualitatively fit the data? Could it do better? \n",
    "\n",
    "> *Your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A83iJUkBujj"
   },
   "source": [
    "(b) Fit a 12th degree polynomial to the data. Does this do qualitatively better or worse than the 2nd degree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VZAQ0PB5Bujj",
    "outputId": "8ff1e140-5ba5-4bc2-bd45-beca34846d2a"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xanWSXvBujk"
   },
   "source": [
    "> *Your response here* This does substantially better than the first model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpDFP-eSBujl"
   },
   "source": [
    "(c) Modify the loop below to estimate the bias-variance tradeoff as model complexity (i.e., degree of the polynomial model, $k$) increases from 2 to 50. Use the training data to fit the model and test data to evaluate its predictive accuracy. Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(**Note**: We are using median accuracies here because there are often 1 or 2 outlier values in the higher degree polynomial models that can throw off the accuracy estimates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lnoZVv4OBujl",
    "outputId": "8c175ab9-5456-4d2f-fe7e-609e0eddadc9"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using regular regression\n",
    "degree = seq(2,50)\n",
    "\n",
    "# Need to setup your output vectors\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    #poly.glm = INSERT LINEAR MODEL WITH POLYNOMIAL TERMS\n",
    "    \n",
    "    yhat_train = predict(poly.glm)\n",
    "    yhat_test  = predict(poly.glm, newdata=df_test)\n",
    "\n",
    "    # Because we get weird outlier predictions plot median sum square error\n",
    "    # Also, k-1 because we are starting with k=2\n",
    "    train_rss[k-1] = median((y_train - yhat_train)^2)\n",
    "    test_rss[k-1] = median((y_test - yhat_test)^2)\n",
    "}\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "# Plot your results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx8zgVDGBujm"
   },
   "source": [
    "What do you see as $k$ increase?\n",
    "\n",
    "> *Your response here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfF6syENBujm"
   },
   "source": [
    "(d) Now copy the code above and let's see what happens when we go beyond $p=n$ (remember, in this case $k=p$). Test polynomial models up to $k=150$. Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree. \n",
    "\n",
    "Use the `geom_vline()` function in `ggplot` to draw a vertical line where $k=n$ (here $n$ is the number of observations in the training set). This will make it clear where we cross the threshold for finding *unique* solutions in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fqk3xlUBBujm",
    "outputId": "5836c161-ded7-4edd-c69b-642c60e55015"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsiaI7CNBujn"
   },
   "source": [
    "What do you see as $k$ gets larger than $n$?\n",
    "\n",
    "> *Your response here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez8Cy8anBujn"
   },
   "source": [
    "---\n",
    "## Applying regularization to the model fits (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFAAGungBujn"
   },
   "source": [
    "Repeat the previous bias-variance tradeoff test, going up to $k=150$, but now use ridge regression with a sparsity parameter of $\\lambda=0.00005$. Plot your results the same way as last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0uVdEguGBujn",
    "outputId": "03df8473-1758-40f2-ab73-bdf086c49378"
   },
   "outputs": [],
   "source": [
    "# Now do the variance-bias trade off analysis using ridge regression\n",
    "lambda=0.00005\n",
    "degree = seq(2,150)\n",
    "\n",
    "rm(train_rss, test_rss)\n",
    "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
    "\n",
    "for (k in degree) {\n",
    "    # WRITE YOUR CODE HERE\n",
    "    #ridge.glm = INSERT RIDGE MODEL WITH POLYNOMIAL TERMS & LAMBDA\n",
    "\n",
    "    yhat_train = predict(ridge.glm, newx=poly(x_train, k, raw=TRUE))\n",
    "    yhat_test  = predict(ridge.glm, newx=poly(x_test, k, raw=TRUE))\n",
    "\n",
    "   # Because we get weird outlier predictions plot median sum square error\n",
    "    train_rss[k-1] = median((y_train - yhat_train)^2)\n",
    "    test_rss[k-1] = median((y_test - yhat_test)^2)\n",
    "}\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "# Plot your results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IF6tO_uBujo"
   },
   "source": [
    "What happens now when $k$ gets larger than $n$?\n",
    "\n",
    "> *Your response here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zheO4rLBujo"
   },
   "source": [
    "## Reflection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-65QvdnBujo"
   },
   "source": [
    "The simulations above should have shown that, when applying a regularization (i.e., a sparsity constraint), the behavior of the bias-variance tradeoff changes. Explain why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkM1H1_WBujo"
   },
   "source": [
    "> *Your response here* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ietUafKfBujo"
   },
   "source": [
    "--- \n",
    "## Bonus (1 extra credit point)\n",
    "Recall that the $p=n$ threshold defines the limit for finding a *unique* solution to $Y=F(X)$ (i.e., there is only one combination of regression coefficients that is *best* at explaining variance in $Y$). With this in mind, what is regularization doing that works around this upper limit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo5eCrpuBujp"
   },
   "source": [
    "> *Your response here* \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmcAxEQCBujp"
   },
   "source": [
    "**DUE:** 5pm EST, April 25, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYdsoRobBujp"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> *Someone's Name*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework10_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
